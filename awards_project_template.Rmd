---
title: "Analyst Intern, Data Science & Solutions Project"
author: "Jiaming Lin"
output:
  html_document: default
  pdf_document: default
---

```{r set options, include=FALSE}
# DO NOT CHANGE THE LINE BELOW 
knitr::opts_chunk$set(echo = TRUE)
```

``` {css styling, echo=FALSE}

<style>
.tocify {
max-width: 175px !important;
}
</style>

<style>
.main-container {
width: 100%;
max-width: 940px;
margin-left: 250px;
margin-right: auto;
}
</style>

<style>
.red-header {
  color: red;
}
</style>

```

```{r logo, echo = FALSE}

htmltools::img(src = 'https://cdn.nba.com/logos/nba/1610612760/primary/L/logo.svg',
                height = '250px',
                alt = 'logo',
                style = 'position: fixed; top: -40px; left: -75px;')
```


# Introduction  

The purpose of this project is to gauge your technical skills and problem solving ability by working through something similar to a real NBA data science project. You will work your way through this R Markdown document, answering questions as you go along. Please begin by adding your name to the "author" key in the YAML header. When you're finished with the document, come back and type your answers into the answer key at the top. Please leave all your work below and have your answers where indicated below as well. Please note that we will be reviewing your code so make it clear, concise and avoid long printouts. Feel free to add in as many new code chunks as you'd like.

Remember that we will be grading the quality of your code and visuals alongside the correctness of your answers. Please try to use the tidyverse as much as possible (instead of base R and explicit loops.)  

**Note:**    

**Throughout this document, any `season` column represents the year each season started. For example, the 2015-16 season will be in the dataset as 2015. For most of the rest of the project, we will refer to a season by just this number (e.g. 2015) instead of the full text (e.g. 2015-16).**   

<h1 class="red-header">Answers</h1>  

## Part 1      

**Question 1:**   

- 1st Team: 25.9 points per game  
- 2nd Team: 23.1 points per game  
- 3rd Team: 20.6 points per game  
- All-Star: 21.6 points per game   

**Question 2:** 4.68 Years  

**Question 3:** 

- Elite: 2 players.  
- All-Star: 1 players.  
- Starter: 10 players.  
- Rotation: 6 players.  
- Roster: 11 players.  
- Out of League: 43 players.  

**Open Ended Modeling Question:** Please show your work and leave all responses below in the document.


## Part 2  

**Question 1:** 28.9%   
**Question 2:** Written question, put answer below in the document.    
**Question 3:** Written question, put answer below in the document.    
  

# Setup and Data    

```{r load data, message = F, warning = F}
library(tidyverse)
library(dplyr)
library(xgboost)
library(caret)
library(ggplot2)
library(pROC)
library(Metrics)
library(irr)
library(pROC)
library(reactable)

# Note, you will likely have to change these paths. If your data is in the same folder as this project, 
# the paths will likely be fixed for you by deleting ../../Data/awards_project/ from each string.
awards <- read_csv("awards_data.csv")
player_data <- read_csv("player_stats.csv")
team_data <- read_csv("team_stats.csv")
rebounding_data <- read_csv("team_rebounding_data_22.csv")
```

## Part 1 -- Awards  

In this section, you're going to work with data relating to player awards and statistics. You'll start with some data manipulation questions and work towards building a model to predict broad levels of career success.  

### Question 1  

**QUESTION:** What is the average number of points per game for players in the 2007-2021 seasons who won All NBA First, Second, and Third teams (**not** the All Defensive Teams), as well as for players who were in the All-Star Game (**not** the rookie all-star game)?

```{r, message=FALSE, warning=FALSE}
# Compute Points Per Game (PPG)
player_data <- player_data %>%
  mutate(PPG = points / games)

# Function to compute average PPG for a given award
compute_avg_ppg <- function(award_column) {
  award_players <- awards %>%
    filter(.data[[award_column]] == 1 & season >= 2007 & season <= 2021) %>%
    select(nbapersonid, season)
  
  avg_ppg <- player_data %>%
    inner_join(award_players, by = c("nbapersonid", "season")) %>%
    summarise(Average_PPG = mean(PPG, na.rm = TRUE)) %>%
    pull(Average_PPG)
  
  return(avg_ppg)
}

# Compute average PPG for each category
first_team_avg_pts <- compute_avg_ppg("All NBA First Team")
second_team_avg_pts <- compute_avg_ppg("All NBA Second Team")
third_team_avg_pts <- compute_avg_ppg("All NBA Third Team")
AS_team_avg_pts <- compute_avg_ppg("all_star_game")
```

<span style="color:red">**ANSWER 1:**</span>  

1st Team: `r first_team_avg_pts` points per game  
2nd Team: `r second_team_avg_pts` points per game  
3rd Team: `r third_team_avg_pts` points per game  
All-Star: `r AS_team_avg_pts` points per game   


### Question 2  

**QUESTION:** What was the average number of years of experience in the league it takes for players to make their first All NBA Selection (1st, 2nd, or 3rd team)? Please limit your sample to players drafted in 2007 or later who did eventually go on to win at least one All NBA selection. For example:

- Luka Doncic is in the dataset as 2 years. He was drafted in 2018 and won his first All NBA award in 2019 (which was his second season).  
- LeBron James is not in this dataset, as he was drafted prior to 2007.  
- Lu Dort is not in this dataset, as he has not received any All NBA honors.  

```{r, message=FALSE, warning=FALSE}
# Filter players drafted in 2007 or later
eligible_players <- player_data %>%
  filter(draftyear >= 2007) %>%
  select(nbapersonid, draftyear)

# Identify players who made their first All-NBA Team selection (1st, 2nd, or 3rd)
all_nba_players <- awards %>%
  filter((`All NBA First Team` == 1 | `All NBA Second Team` == 1 | `All NBA Third Team` == 1)) %>%
  select(nbapersonid, season)

# Merge to get draft year for All-NBA players
all_nba_players <- all_nba_players %>%
  inner_join(eligible_players, by = "nbapersonid") %>%
  mutate(years_to_first_all_nba = season - draftyear)

# Find the first All-NBA selection per player
first_all_nba <- all_nba_players %>%
  group_by(nbapersonid) %>%
  summarise(first_all_nba_years = min(years_to_first_all_nba), .groups = "drop")

# Compute the average number of years in the league before first All-NBA selection
avg_selection_year <- mean(first_all_nba$first_all_nba_years + 1, na.rm = TRUE)
```

<span style="color:red">**ANSWER 2:**</span>  

`r avg_selection_year` Years  


## Data Cleaning Interlude  

You're going to work to create a dataset with a "career outcome" for each player, representing the highest level of success that the player achieved for **at least two** seasons *after his first four seasons in the league* (examples to follow below!). To do this, you'll start with single season level outcomes. On a single season level, the outcomes are:  

- Elite: A player is "Elite" in a season if he won any All NBA award (1st, 2nd, or 3rd team), MVP, or DPOY in that season.    
- All-Star: A player is "All-Star" in a season if he was selected to be an All-Star that season.   
- Starter:  A player is a "Starter" in a season if he started in at least 41 games in the season OR if he played at least 2000 minutes in the season.    
- Rotation:  A player is a "Rotation" player in a season if he played at least 1000 minutes in the season.   
- Roster:  A player is a "Roster" player in a season if he played at least 1 minute for an NBA team but did not meet any of the above criteria.     
- Out of the League: A player is "Out of the League" if he is not in the NBA in that season.   

We need to make an adjustment for determining Starter/Rotation qualifications for a few seasons that didn't have 82 games per team. Assume that there were 66 possible games in the 2011 lockout season and 72 possible games in each of the 2019 and 2020 seasons that were shortened due to covid. Specifically, if a player played 900 minutes in 2011, he **would** meet the rotation criteria because his final minutes would be considered to be 900 * (82/66) = 1118. Please use this math for both minutes and games started, so a player who started 38 games in 2019 or 2020 would be considered to have started 38 * (82/72) = 43 games, and thus would qualify for starting 41. Any answers should be calculated assuming you round the multiplied values to the nearest whole number.

Note that on a season level, a player's outcome is the highest level of success he qualifies for in that season. Thus, since Shai Gilgeous-Alexander was both All-NBA 1st team and an All-Star last year, he would be considered to be "Elite" for the 2022 season, but would still qualify for a career outcome of All-Star if in the rest of his career he made one more All-Star game but no more All-NBA teams. Note this is a hypothetical, and Shai has not yet played enough to have a career outcome.   

Examples:  

- A player who enters the league as a rookie and has season outcomes of Roster (1), Rotation (2), Rotation (3), Roster (4), Roster (5), Out of the League (6+) would be considered "Out of the League," because after his first four seasons, he only has a single Roster year, which does not qualify him for any success outcome.  
- A player who enters the league as a rookie and has season outcomes of Roster (1), Rotation (2), Starter (3), Starter (4), Starter (5), Starter (6), All-Star (7), Elite (8), Starter (9) would be considered "All-Star," because he had at least two seasons after his first four at all-star level of production or higher.  
- A player who enters the league as a rookie and has season outcomes of Roster (1), Rotation (2), Starter (3), Starter (4), Starter (5), Starter (6), Rotation (7), Rotation (8), Roster (9) would be considered a "Starter" because he has two seasons after his first four at a starter level of production. 

### Question 3  

**QUESTION:** There are 73 players in the `player_data` dataset who have 2010 listed as their draft year. How many of those players have a **career** outcome in each of the 6 buckets?  

```{r, message=FALSE, warning=FALSE}
# Adjust games/minutes for shortened seasons (2011: 66 games, 2019/2020: 72 games)
adjusted_minutes_games <- function(df) {
  df <- df %>%
    mutate(
      adj_games = case_when(
        season == 2011 ~ games * (82 / 66),
        season %in% c(2019, 2020) ~ games * (82 / 72),
        TRUE ~ games
      ),
      adj_minutes = case_when(
        season == 2011 ~ mins * (82 / 66),
        season %in% c(2019, 2020) ~ mins * (82 / 72),
        TRUE ~ mins
      ),
      adj_games_start = case_when(
        season == 2011 ~ games_start * (82 / 66),  # Adjust for 66-game season
        season %in% c(2019, 2020) ~ games_start * (82 / 72),  # Adjust for 72-game seasons
        TRUE ~ games_start
      )
    )
  return(df)
}

# Apply adjustments
player_data <- adjusted_minutes_games(player_data)

# Filter for players drafted in 2010
draft_2010_players <- player_data %>%
  filter(draftyear == 2010) %>%
  select(nbapersonid, season, adj_games, adj_minutes, adj_games_start)

# Assign season-level outcomes
season_outcomes <- draft_2010_players %>%
  left_join(awards, by = c("nbapersonid", "season")) %>%
  mutate(
    outcome = case_when(
      (`All NBA First Team` == 1 | `All NBA Second Team` == 1 | `All NBA Third Team` == 1 | 
       `Most Valuable Player_rk` == 1 | `Defensive Player Of The Year_rk` == 1) ~ "Elite",
      (all_star_game == TRUE) ~ "All-Star",
      (adj_games_start >= 41 | adj_minutes >= 2000) ~ "Starter",  # Now correctly adjusted
      (adj_minutes >= 1000) ~ "Rotation",
      (adj_minutes >= 1) ~ "Roster",
      TRUE ~ "Out of the League"
    )
  )

# Determine career outcomes (ignore first 4 seasons, count at least 2 years in a category)
career_outcomes <- season_outcomes %>%
  group_by(nbapersonid) %>%
  filter(season > (min(season) + 3)) %>%  # Ignore first 4 seasons
  count(outcome) %>%
  filter(n >= 2) %>%
  summarise(career_outcome = case_when(
    "Elite" %in% outcome ~ "Elite",
    "All-Star" %in% outcome ~ "All-Star",
    "Starter" %in% outcome ~ "Starter",
    "Rotation" %in% outcome ~ "Rotation",
    "Roster" %in% outcome ~ "Roster",
    TRUE ~ "Out of the League"
  ))

# Ensure all 73 players are included
all_players_2010 <- player_data %>%
  filter(draftyear == 2010) %>%
  distinct(nbapersonid)

career_outcome_counts <- all_players_2010 %>%
  left_join(career_outcomes, by = "nbapersonid") %>%
  mutate(career_outcome = ifelse(is.na(career_outcome), "Out of the League", career_outcome)) %>%
  count(career_outcome)

# Print result
print(career_outcome_counts)


```

<span style="color:red">**ANSWER 3:**</span>    

Elite: 2 players.  
All-Star: 1 players.  
Starter: 10 players.  
Rotation: 6 players.  
Roster: 11 players.  
Out of League: 43 players.  

### Open Ended Modeling Question   

In this question, you will work to build a model to predict a player's career outcome based on information up through the first four years of his career. 

This question is intentionally left fairly open ended, but here are some notes and specifications.  

1. We know modeling questions can take a long time, and that qualified candidates will have different levels of experience with "formal" modeling. Don't be discouraged. It's not our intention to make you spend excessive time here. If you get your model to a good spot but think you could do better by spending a lot more time, you can just write a bit about your ideas for future improvement and leave it there. Further, we're more interested in your thought process and critical thinking than we are in specific modeling techniques. Using smart features is more important than using fancy mathematical machinery, and a successful candidate could use a simple regression approach. 

2. You may use any data provided in this project, but please do not bring in any external sources of data. Note that while most of the data provided goes back to 2007, All NBA and All Rookie team voting is only included back to 2011.  

3. A player needs to complete at least three additional seasons after their first four to be considered as having a distinct career outcome for our dataset. (We are using 3+ instead of 2+ just to give each player a little more time to accumulate high level seasons before we classify his career). Because the dataset in this project ends in 2021, this means that a player would need to have had the chance to play in the '21, '20, and '19 seasons after his first four years, and thus his first four years would have been '18, '17, '16, and '15. **For this reason, limit your training data to players who were drafted in or before the 2015 season.** Karl-Anthony Towns was the #1 pick in that season.  

4. Once you build your model, predict on all players who were drafted in 2018-2021 (They have between 1 and 4 seasons of data available and have not yet started accumulating seasons that inform their career outcome).  

5. You can predict a single career outcome for each player, but it's better if you can predict the probability that each player falls into each outcome bucket.    

6. Include, as part of your answer:  
  - A brief written overview of how your model works, targeted towards a decision maker in the front office without a strong statistical background. 
  - What you view as the strengths and weaknesses of your model.  
  - How you'd address the weaknesses if you had more time and or more data.  
  - A ggplot or ggplotly visualization highlighting some part of your modeling process, the model itself, or your results.  
  - Your predictions for Shai Gilgeous-Alexander, Zion Williamson, James Wiseman, and Josh Giddey.  
  - (Bonus!) An html table (for example, see the package `reactable`) containing all predictions for the players drafted in 2019-2021.  


```{r, message=FALSE, warning=FALSE}
# Determine season-level classification
classify_season <- function(stats, awards) {
  stats <- stats %>% 
    left_join(awards, by = c("season", "nbapersonid")) %>%
    mutate(
      category = case_when(
        `All NBA First Team` == 1 | `All NBA Second Team` == 1 | 
          `All NBA Third Team` == 1 | `Most Valuable Player_rk` == 1 | 
          `Defensive Player Of The Year_rk` == 1 ~ "Elite",
        all_star_game == TRUE ~ "All-Star",
        adj_games_start >= 41 | adj_minutes >= 2000 ~ "Starter",
        adj_minutes >= 1000 ~ "Rotation",
        mins >= 1 ~ "Roster",
        TRUE ~ "Out of the League"
      )
    )
  return(stats)
}

classified_data <- classify_season(player_data, awards)





determine_career_outcome <- function(df) {
  # Assign season number for each player based on nbapersonid
  df <- df %>% 
    group_by(nbapersonid, draftyear) %>% 
    arrange(season) %>%
    mutate(season_number = row_number()) %>% 
    ungroup()
  
  # Identify players who played ≤ 4 seasons and classify them as "Out of the League"
  short_career_players <- df %>% 
    group_by(nbapersonid, draftyear) %>%
    summarise(
      max_outcome = "Out of the League",
      elite_count = 0, 
      all_star_count = 0, 
      starter_count = 0, 
      rotation_count = 0, 
      roster_count = 0
    ) %>%
    filter(!nbapersonid %in% df$nbapersonid[df$season_number > 4]) # Exclude players with >4 seasons
  
  # Filter for players who played more than 4 seasons
  df_filtered <- df %>% filter(season_number > 4)
  
  # Calculate career outcome for players who played >4 seasons
  career_outcomes <- df_filtered %>% 
    group_by(nbapersonid, draftyear) %>%
    summarise(
      elite_count = sum(category == "Elite"),
      all_star_count = sum(category == "All-Star"),
      starter_count = sum(category == "Starter"),
      rotation_count = sum(category == "Rotation"),
      roster_count = sum(category == "Roster"),
      max_outcome = case_when(
        elite_count >= 2 ~ "Elite",
        all_star_count >= 2 ~ "All-Star",
        starter_count >= 2 ~ "Starter",
        rotation_count >= 2 ~ "Rotation",
        roster_count >= 2 ~ "Roster",
        TRUE ~ "Out of the League"
      )
    )
  
  # Combine both datasets
  final_career_outcomes <- bind_rows(career_outcomes, short_career_players)
  
  return(final_career_outcomes)
}

# Run the function and save the output
career_outcomes <- determine_career_outcome(classified_data)






# Merge player stats with awards data
merged_data <- player_data %>% 
  left_join(awards, by = c("season", "nbapersonid"))

# Filter to only include the first four seasons after draft year
filtered_data <- merged_data %>% 
  filter(season - draftyear <= 4)

# Prepare full dataset
full_data <- filtered_data %>% 
  group_by(nbapersonid, player, draftyear) %>%
  summarise(
    avg_mins = mean(mins, na.rm = TRUE),
    avg_games = mean(games, na.rm = TRUE),
    avg_games_start = mean(games_start, na.rm = TRUE),
    avg_ws = mean(WS, na.rm = TRUE),
    avg_vorp = mean(VORP, na.rm = TRUE),
    avg_per = mean(PER, na.rm = TRUE),
    avg_usg = mean(usg, na.rm = TRUE),
    avg_ast = mean(ast, na.rm = TRUE),
    avg_stl = mean(steals, na.rm = TRUE),
    avg_blk = mean(blocks, na.rm = TRUE),
    avg_tov = mean(tov, na.rm = TRUE),
    avg_pts = mean(points, na.rm = TRUE),
    total_all_star = sum(all_star_game, na.rm = TRUE),
    total_all_nba = sum(`All NBA First Team` + `All NBA Second Team` + `All NBA Third Team`, na.rm = TRUE),
    total_awards = sum(`Most Valuable Player_rk` == 1, `Defensive Player Of The Year_rk` == 1, na.rm = TRUE),
    total_defensive_team = sum(`All NBA Defensive First Team` + `All NBA Defensive Second Team`, na.rm = TRUE),
    total_rookie_team = sum(`All Rookie First Team` + `All Rookie Second Team`, na.rm = TRUE),
    total_player_of_week = sum(`Player Of The Week`, na.rm = TRUE),
    total_rookie_of_month = sum(`Rookie Of The Month`, na.rm = TRUE)
  ) %>%
  ungroup() %>% 
  left_join(career_outcomes %>% select(nbapersonid, draftyear, max_outcome), 
            by = c("nbapersonid", "draftyear"))
```

```{r, message=FALSE, warning=FALSE}
# Convert categorical target variable to factor and define ordinal levels
full_data$max_outcome <- factor(full_data$max_outcome, 
                                levels = c("Out of the League", "Roster", "Rotation", "Starter", "All-Star", "Elite"), 
                                ordered = TRUE)

# Split data into train, validation, test, and prediction
train_data <- full_data %>% filter(draftyear >= 2007 & draftyear <= 2012)
val_data <- full_data %>% filter(draftyear >= 2013 & draftyear <= 2014)
test_data <- full_data %>% filter(draftyear == 2015)
predict_data <- full_data %>% filter(draftyear >= 2018 & draftyear <= 2021)

# Prepare X and y matrices
train_x <- train_data %>% select(where(is.numeric)) %>% select(-nbapersonid, -draftyear) %>% as.matrix()
train_y <- as.numeric(train_data$max_outcome) - 1  # Convert factor to numeric starting at 0
val_x <- val_data %>% select(where(is.numeric)) %>% select(-nbapersonid, -draftyear) %>% as.matrix()
val_y <- as.numeric(val_data$max_outcome) - 1
test_x <- test_data %>% select(where(is.numeric)) %>% select(-nbapersonid, -draftyear) %>% as.matrix()
test_y <- as.numeric(test_data$max_outcome) - 1

# Expanded grid search hyperparameter space
search_grid <- expand.grid(
  max_depth = c(3, 4, 5, 6, 7),
  eta = c(0.001, 0.01, 0.05, 0.1, 0.2),
  subsample = c(0.5, 0.6, 0.7, 0.8, 0.9),
  colsample_bytree = c(0.5, 0.6, 0.7, 0.8, 0.9),
  lambda = c(0.1, 1, 5, 10),
  alpha = c(0, 0.5, 1, 5)
)

# Randomly sample a subset for efficient tuning
set.seed(42)
search_grid <- search_grid %>% sample_n(20)  # Randomly sample 20 configurations

best_params <- NULL
best_accuracy <- 0

# Grid search loop
for (i in 1:nrow(search_grid)) {
  params <- list(
    objective = "multi:softprob",
    num_class = length(levels(full_data$max_outcome)),
    eval_metric = "mlogloss",
    max_depth = search_grid$max_depth[i],
    eta = search_grid$eta[i],
    subsample = search_grid$subsample[i],
    colsample_bytree = search_grid$colsample_bytree[i],
    lambda = search_grid$lambda[i],
    alpha = search_grid$alpha[i],
    seed = 42
  )
  
  train_matrix <- xgb.DMatrix(data = train_x, label = train_y)
  val_matrix <- xgb.DMatrix(data = val_x, label = val_y)
  model <- xgb.train(params = params, data = train_matrix, 
                     nrounds = 500, 
                     watchlist = list(val = val_matrix), 
                     early_stopping_rounds = 15, 
                     verbose = 0)
  
  val_preds <- predict(model, val_matrix)
  val_preds_matrix <- matrix(val_preds, ncol = length(levels(full_data$max_outcome)), byrow = TRUE)
  val_predictions <- max.col(val_preds_matrix) - 1
  val_accuracy <- mean(val_predictions == val_y)
  
  if (val_accuracy > best_accuracy) {
    best_accuracy <- val_accuracy
    best_params <- params
  }
}

# Train final model with best parameters
train_matrix <- xgb.DMatrix(data = train_x, label = train_y)
val_matrix <- xgb.DMatrix(data = val_x, label = val_y)
test_matrix <- xgb.DMatrix(data = test_x, label = test_y)
xgb_model <- xgb.train(params = best_params, data = train_matrix, 
                       nrounds = 500, 
                       watchlist = list(train = train_matrix, val = val_matrix), 
                       early_stopping_rounds = 20, 
                       verbose = 0)

# Extract evaluation log
eval_log <- xgb_model$evaluation_log

eval_log_long <- eval_log %>%
  pivot_longer(cols = -iter, names_to = "dataset", values_to = "logloss")

# Plot the log loss reduction over training rounds
ggplot(eval_log_long, aes(x = iter, y = logloss, color = dataset)) +
  geom_line(size = 1) +
  labs(title = "XGBoost Training and Validation Loss Over Rounds",
       x = "Number of Rounds",
       y = "Log Loss",
       color = "Dataset") +
  theme_minimal()


# Calculate validation accuracy
val_preds <- predict(xgb_model, val_matrix)
val_preds_matrix <- matrix(val_preds, ncol = length(levels(full_data$max_outcome)), byrow = TRUE)
val_predictions <- max.col(val_preds_matrix) - 1
val_accuracy <- mean(val_predictions == val_y)
print(paste("Validation Accuracy:", val_accuracy))

# Calculate test accuracy
test_preds <- predict(xgb_model, test_matrix)
test_preds_matrix <- matrix(test_preds, ncol = length(levels(full_data$max_outcome)), byrow = TRUE)
test_predictions <- max.col(test_preds_matrix) - 1
test_accuracy <- mean(test_predictions == test_y)
print(paste("Test Accuracy:", test_accuracy))

# Feature Importance Analysis
importance_matrix <- xgb.importance(feature_names = colnames(train_x), model = xgb_model)

# Plot Feature Importance
ggplot(importance_matrix, aes(x = reorder(Feature, Gain), y = Gain)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  labs(title = "Feature Importance", x = "Features", y = "Importance (Gain)")



# Convert test labels to factor with proper levels
test_y_named <- factor(test_y, levels = 0:5, 
                       labels = c("Out of the League", "Roster", "Rotation", "Starter", "All-Star", "Elite"))

# Ensure predicted probability matrix has correct column names matching levels
colnames(test_preds_matrix) <- levels(test_y_named)

# Compute AUC-ROC using one-vs-all (OvR) method
auc_score_test <- multiclass.roc(test_y_named, test_preds_matrix)

# Print AUC-ROC score
print(paste("Test AUC-ROC: Measures how well the model distinguishes between classes (closer to 1 is better):", auc_score_test$auc))
```

```{r}
# Get feature names from training data
train_feature_names <- colnames(train_x)

# Ensure predict_data has the same columns as train_x
predict_x <- predict_data %>%
  select(all_of(train_feature_names)) %>%  # Select only matching features
  replace(is.na(.), 0) %>%  # Replace NA values with 0
  as.matrix()

# Convert predict_x to xgb.DMatrix
predict_matrix <- xgb.DMatrix(data = predict_x)

# Make predictions
pred_probs <- predict(xgb_model, predict_matrix)

# Reshape predictions into a matrix
pred_probs_matrix <- matrix(pred_probs, 
                            ncol = 6, 
                            byrow = TRUE)

# Assign correct column names
colnames(pred_probs_matrix) <- c("Out of the League", "Roster", "Rotation", "Starter", "All-Star", "Elite")

# Get the predicted career outcome (highest probability)
predicted_outcome <- apply(pred_probs_matrix, 1, function(x) colnames(pred_probs_matrix)[which.max(x)])

# Combine results into a data frame
pred_results <- predict_data %>%
  select(player, draftyear) %>%
  bind_cols(as.data.frame(pred_probs_matrix)) %>%
  mutate(Predicted_Career_Outcome = predicted_outcome)

# Create an interactive reactable table
reactable(pred_results, 
          columns = list(
            player = colDef(name = "Player"),
            draftyear = colDef(name = "Draft Year"),
            Predicted_Career_Outcome = colDef(name = "Predicted Career Outcome"),
            `Out of the League` = colDef(name = "Out of League Probability", format = colFormat(digits = 3)),
            Roster = colDef(name = "Roster Probability", format = colFormat(digits = 3)),
            Rotation = colDef(name = "Rotation Probability", format = colFormat(digits = 3)),
            Starter = colDef(name = "Starter Probability", format = colFormat(digits = 3)),
            `All-Star` = colDef(name = "All-Star Probability", format = colFormat(digits = 3)),
            Elite = colDef(name = "Elite Probability", format = colFormat(digits = 3))
          ),
          searchable = TRUE,
          filterable = TRUE,
          pagination = TRUE,
          highlight = TRUE,
          striped = TRUE,
          bordered = TRUE,
          defaultSorted = list(Predicted_Career_Outcome = "desc")
)


```

<span style="color:red">**ANSWER:**</span>    

  - The model is trained using XGBoost for multi-class classification, where the target variable (career outcome) is converted into an ordered factor and split into training, validation, test, and prediction sets based on draft years. A grid search with random sampling is used to find the best hyperparameters, optimizing values for tree depth, learning rate, subsampling, and regularization. The model is trained on the 2007-2012 draft data, while the 2013-2014 data is used for validation. During training, early stopping prevents overfitting by halting when validation loss stops improving. The final model is then evaluated on the 2015 test set to assess its generalization. A log-loss curve is plotted to track model performance, and the trained model is later used for predicting outcomes of 2018-2021 draft classes. This process ensures a well-tuned, high-performing model capable of accurately predicting player success levels.

  - Strengths and weaknesses: The model has several key strengths. First, it effectively handles non-linearity, meaning it can model complex relationships between player statistics and future success, which traditional linear models might miss. Second, XGBoost captures feature interactions, allowing it to automatically learn how different stats and awards interact to influence outcomes, rather than assuming each feature acts independently. Third, XGBoost can handle missing data efficiently, using built-in mechanisms to make reasonable splits even when some values are absent, reducing the need for extensive preprocessing. Finally, it is robust to multicollinearity, meaning it does not suffer from issues when features are highly correlated, unlike traditional regression models where multicollinearity can distort coefficient estimates.However, the model also has some notable weaknesses. One major limitation is that it does not account for player improvement over time—it relies on a player’s cumulative stats over four years rather than tracking year-to-year development, potentially missing key growth patterns. Second, XGBoost is less interpretable than an ordinal logistic regression (OLR) model, as it does not provide clear coefficient estimates that explain the impact of each feature. Lastly, XGBoost does not inherently respect the ordinal nature of the target variable, meaning it treats the outcome categories (e.g., "Out of the League," "Roster," "Rotation," etc.) as independent classes rather than recognizing their natural ranking. In other words, it does not consider that misclassifying a player as "Out of the League" instead of "Rotation" is a smaller error than misclassifying them as "Elite." Instead, XGBoost applies a multi-class classification approach, which assumes all categories are equally different from each other. This can lead to suboptimal predictions because the model might assign probabilities in a way that does not reflect the ordinal relationships.
  
  - If I had more time and data, I would address the model’s weaknesses by incorporating player improvement over time rather than relying on cumulative four-year stats. By using yearly performance data, the model could track growth trends and identify how a player’s development trajectory influences their future success. Additionally, I would explore other models, particularly ordinal logistic regression (OLR), to compare its performance with XGBoost. OLR inherently respects the ordered nature of the target variable, which might lead to more meaningful predictions. By comparing both models, I could evaluate the trade-off between interpretability and predictive power, determining whether the added complexity of XGBoost provides a significant advantage over a simpler, more interpretable model. These enhancements would improve the model’s ability to capture player development and provide more structured ordinal predictions.

## Part 2 -- Predicting Team Stats  

In this section, we're going to introduce a simple way to predict team offensive rebound percent in the next game and then discuss ways to improve those predictions.  
 
### Question 1   

Using the `rebounding_data` dataset, we'll predict a team's next game's offensive rebounding percent to be their average offensive rebounding percent in all prior games. On a single game level, offensive rebounding percent is the number of offensive rebounds divided by their number offensive rebound "chances" (essentially the team's missed shots). On a multi-game sample, it should be the total number of offensive rebounds divided by the total number of offensive rebound chances.    

Please calculate what OKC's predicted offensive rebound percent is for game 81 in the data. That is, use games 1-80 to predict game 81.  

```{r}
okc_rebounding_data <- filter(rebounding_data, team == "OKC")
okc_rebounding_data <- filter(okc_rebounding_data, game_number <= 80)
sum(okc_rebounding_data$offensive_rebounds) / sum(okc_rebounding_data$off_rebound_chances) 
```

<span style="color:red">**ANSWER 1:**</span>    

28.9% 

### Question 2  

There are a few limitations to the method we used above. For example, if a team has a great offensive rebounder who has played in most games this season but will be out due to an injury for the next game, we might reasonably predict a lower team offensive rebound percent for the next game.  

Please discuss how you would think about changing our original model to better account for missing players. You do not have to write any code or implement any changes, and you can assume you have access to any reasonable data that isn't provided in this project. Try to be clear and concise with your answer.  

<span style="color:red">**ANSWER 2:**</span>

  - The easiest way to handle this situation is using the historical offensive rebounding percent when that player is not on the court. Although we probably do not have that much data since that player played most of the games, we can calculate this by minutes since he cannot play 48 minutes every game.

### Question 3  

In question 2, you saw and discussed how to deal with one weakness of the model. For this question, please write about 1-3 other potential weaknesses of the simple average model you made in question 1 and discuss how you would deal with each of them. You may either explain a weakness and discuss how you'd fix that weakness, then move onto the next issue, or you can start by explaining multiple weaknesses with the original approach and discuss one overall modeling methodology you'd use that gets around most or all of them. Again, you do not need to write any code or implement any changes, and you can assume you have access to any reasonable data that isn't provided in this project. Try to be clear and concise with your answer.  

<span style="color:red">**ANSWER 3:**</span>    

  - First weakness: The prediction can be inaccurate if the next opponent team is very good or bad at rebounding. Potential solution: We can use historical offensive rebounding percent with that opponent team to make prediction.
  
  - Second weakness: The prediction can be inaccurate for the back-to-back game since players might be tired. Potential solution: We can use historical offensive rebounding percent separately for back-to-back and other games to make predictions.


